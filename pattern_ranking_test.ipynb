{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import get_miner\n",
    "from log_parsing import from_id_to_template\n",
    "import joblib\n",
    "from data_integrate import *\n",
    "from pattern_miner import *\n",
    "import pattern_ranker as pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_template_miner = get_miner()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "error ids: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict = joblib.load('output/fault_free_eventgraphs.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict2 = joblib.load('output/fault_suffering_eventgraphs.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extract_expected_events(results, fault_free_pattern):\n",
    "    for r in results:\n",
    "        key = r['events']\n",
    "        for key_faultfree in fault_free_pattern.keys():\n",
    "            if key.split('_')[0] == key_faultfree.split('_')[0]:\n",
    "                if key.split('_')[1] != key_faultfree.split('_')[1]:\n",
    "                    if not any([r_entry['events'] == key_faultfree for r_entry in results]):\n",
    "                        r['events_expected'] = key_faultfree\n",
    "                break\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abnormal_pattern_ranker_custom(normal_pattern_dict, abnormal_pattern_dict):\n",
    "    score_dict = {}\n",
    "    for key in abnormal_pattern_dict.keys():\n",
    "        if key in normal_pattern_dict.keys():\n",
    "            score = (2.0 * abnormal_pattern_dict[key] / (abnormal_pattern_dict[key] + normal_pattern_dict[key]) - 1)\n",
    "            if score != 0:\n",
    "                score_dict[key] = score\n",
    "        else:\n",
    "            score_dict[key] = 1.0\n",
    "\n",
    "    return score_dict\n",
    "\n",
    "global_abnormal_patterns = {}\n",
    "\n",
    "def pattern_ranker_custom(fault_free_pattern, fault_suffering_event_graphs, fault_suffering_pattern, log_template_miner, topk=10, min_diff=1):\n",
    "    actual_comparedto_faultfree = abnormal_pattern_ranker_custom(\n",
    "        fault_free_pattern, fault_suffering_pattern)\n",
    "    error_eventids = [185, 187, 188, 189, 201, 204, 205, 207, 208, 209]\n",
    "    \n",
    "    patterns_noerror =  {\n",
    "        k: v for k, v in actual_comparedto_faultfree.items() \n",
    "        if not any(str(id_) in k.split('_') for id_ in error_eventids)\n",
    "    }\n",
    "    \n",
    "    patterns_error =  {\n",
    "        k: v for k, v in actual_comparedto_faultfree.items() \n",
    "        if any(str(id_) in k.split('_') for id_ in error_eventids)\n",
    "    }\n",
    "\n",
    "    reuslts_noerror = pattern_ranker_fromscore(patterns_noerror, fault_suffering_event_graphs, log_template_miner, topk)\n",
    "    reuslts_error = pattern_ranker_fromscore(patterns_error, fault_suffering_event_graphs, log_template_miner, topk)\n",
    "    reuslts_noerror = extract_expected_events(reuslts_noerror, fault_free_pattern)\n",
    "    reuslts_error = extract_expected_events(reuslts_error, fault_free_pattern)\n",
    "    \n",
    "    return reuslts_noerror[0:topk], reuslts_error\n",
    "\n",
    "def pattern_ranker_fromscore(abnormal_pattern_score, fault_suffering_event_graphs, log_template_miner, topk=10):\n",
    "    move_list = set()\n",
    "    for key in abnormal_pattern_score.keys():\n",
    "        # only consider the root of child graph\n",
    "        log_var = from_id_to_template(int(key.split(\"_\")[1]),log_template_miner)\n",
    "        if \"Cpu\" not in log_var and \"Network\" not in log_var and \"Memory\" not in log_var:\n",
    "            for key1 in abnormal_pattern_score.keys():\n",
    "                if int(key.split(\"_\")[0]) == int(key1.split(\"_\")[1]) and abs(abnormal_pattern_score[key]) <= abs(abnormal_pattern_score[key1]):\n",
    "                    move_list.add(key)\n",
    "    for item in move_list:\n",
    "        abnormal_pattern_score.pop(item)\n",
    "\n",
    "    result_list = []\n",
    "    deepth_dict = {}\n",
    "    for key, value in abnormal_pattern_score.items():\n",
    "        deepth, pod = get_event_depth_pod(fault_suffering_event_graphs, key)\n",
    "        \n",
    "        if pod not in deepth_dict:\n",
    "            deepth_dict[pod] = {}\n",
    "        if key not in deepth_dict[pod]:\n",
    "            deepth_dict[pod][key] = deepth\n",
    "        elif deepth_dict[pod][key] < deepth:\n",
    "            deepth_dict[pod][key] = deepth\n",
    "\n",
    "        if pod == \"\":\n",
    "            deepth = 1\n",
    "            pod = \"frontend-579b9bff58-t2dbm\"\n",
    "\n",
    "        result_list.append({\"events\": key, \"score\": value,\n",
    "                                \"deepth\": deepth, \"pod\": pod})\n",
    "\n",
    "    # if many alarm in one service instane, only persistent the deepest one\n",
    "    move_list = set()\n",
    "    alarm_eventids=['184', '92']\n",
    "    for key_pod in deepth_dict.keys():\n",
    "        pod_events = deepth_dict[key_pod]\n",
    "            # Filter keys that contain any of the target ids\n",
    "        matching_keys = {k: v for k, v in pod_events.items() \n",
    "                    if any(id in k for id in alarm_eventids)}\n",
    "    \n",
    "        # If no matches found, return None\n",
    "        if not matching_keys:\n",
    "            continue\n",
    "\n",
    "        # Return the key with maximum depth value\n",
    "        deepest_key = max(matching_keys.items(), key=lambda x: x[1])[0]\n",
    "            # Create move list with all matching keys except the deepest\n",
    "        for key in matching_keys.keys():\n",
    "            if matching_keys[key] < matching_keys[deepest_key]:\n",
    "                move_list.add(key)\n",
    "\n",
    "    result_list = [d for d in result_list if d['events'] not in move_list]\n",
    "\n",
    "    # if score is the same, deeper is prefer\n",
    "    result_list = sorted(result_list, key=lambda i: (\n",
    "        abs(i['score']), i['deepth']), reverse=True)\n",
    "    \n",
    "    return result_list[0:topk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fault_free_pattern = get_pattern_support(res_dict['2022-08-22 03:51'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'checkoutservice-578fcf4766-9csqn'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_dict2['2022-08-22 05:02']['inject_pod']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fault_suffering_event_graphs = res_dict2['2022-08-22 05:02']['event_graphs']\n",
    "fault_suffering_pattern = get_pattern_support(fault_suffering_event_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pattern_ranker_custom(fault_free_pattern, fault_suffering_event_graphs, fault_suffering_pattern, log_template_miner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'events': '2_185',\n",
       "  'score': 1.0,\n",
       "  'deepth': 1,\n",
       "  'pod': 'frontend-579b9bff58-t2dbm',\n",
       "  'events_expected': '2_82'},\n",
       " {'events': '153_188',\n",
       "  'score': 1.0,\n",
       "  'deepth': 1,\n",
       "  'pod': 'frontend-579b9bff58-t2dbm',\n",
       "  'events_expected': '153_154'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
